{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "\n",
    "from imutils import paths\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"imagenet_class_index.json\", \"r\") as read_file:\n",
    "    imagenet_labels = json.load(read_file)\n",
    "    \n",
    "MAPPING_DICT = {}\n",
    "LABEL_NAMES = {}\n",
    "for label_id in list(imagenet_labels.keys()):\n",
    "    MAPPING_DICT[imagenet_labels[label_id][0]] = int(label_id)\n",
    "    LABEL_NAMES[int(label_id)] = imagenet_labels[label_id][1]\n",
    "\n",
    "IMAGENET_VAL_PATHS = list(paths.list_images(\"val\"))\n",
    "IMAGENET_VAL_PATHS_1k = np.random.choice(IMAGENET_VAL_PATHS, 1000)\n",
    "\n",
    "f = open(\"IMAGENET_VAL_PATHS_1k.pkl\", \"wb\")\n",
    "f.write(pickle.dumps(IMAGENET_VAL_PATHS_1k))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_path, image_size=224):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, 3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)  \n",
    "    image = tf.image.resize(image, (image_size, image_size))\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def preprocess_cutout(image_path, factor, image_size=224):\n",
    "    total_area = image_size * image_size\n",
    "    area = total_area * factor\n",
    "    \n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, 3)\n",
    "    image = tf.image.resize(image, (image_size, image_size))\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "   \n",
    "    transform = A.Compose([\n",
    "        A.Cutout(num_holes=1, max_h_size=int(np.sqrt(area)), \n",
    "                      max_w_size=int(np.sqrt(area)), \n",
    "                      always_apply=True,\n",
    "                      p=1.)\n",
    "    ])\n",
    "    \n",
    "    image = transform(image=image.numpy())[\"image\"]\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)  \n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate without CutOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIT_URL = \"https://tfhub.dev/google/bit/m-r101x3/ilsvrc2012_classification/1\"\n",
    "imagenet_module = tf.keras.Sequential([hub.KerasLayer(BIT_URL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(factor=None):\n",
    "    correct_image_paths = []\n",
    "\n",
    "    for image_path in tqdm(IMAGENET_VAL_PATHS_1k):\n",
    "        if factor:\n",
    "            image = preprocess_cutout(image_path, factor)\n",
    "        else:\n",
    "            image = preprocess(image_path)\n",
    "        label_idx = MAPPING_DICT[image_path.split(\"/\")[1]]\n",
    "        logits = imagenet_module.predict(image)\n",
    "        prob = tf.nn.softmax(imagenet_module.predict(image), 1)\n",
    "        prediction = tf.math.argmax(prob, 1).numpy().tolist()[0]\n",
    "\n",
    "        if label_idx == prediction:\n",
    "            correct_image_paths.append(image_path)\n",
    "\n",
    "    print(f\"Total corrects: {len(correct_image_paths)} out of {len(IMAGENET_VAL_PATHS_1k)}\")\n",
    "    return len(correct_image_paths) / len(IMAGENET_VAL_PATHS_1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223b31c9c0e34b7093be1883b791e3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corrects: 790 out of 1000\n",
      "0.79\n"
     ]
    }
   ],
   "source": [
    "print(evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with CutOut at varying levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1140ce00a541b5b2c417f0cb894686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corrects: 760 out of 1000\n",
      "0.05: 0.76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7c003cb2de49b4a2f57c345040b1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corrects: 750 out of 1000\n",
      "0.1: 0.75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799af6efb6544dc6b0a411ae6f1bb834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corrects: 724 out of 1000\n",
      "0.2: 0.724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195aa91eda0241849c4e44b6225f8640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corrects: 520 out of 1000\n",
      "0.5: 0.52\n"
     ]
    }
   ],
   "source": [
    "factors = [0.05, 0.1, 0.2, 0.5]\n",
    "factors_dict = {}\n",
    "\n",
    "for factor in factors:\n",
    "    top_1_acc = evaluate(factor)\n",
    "    factors_dict[factor] = top_1_acc\n",
    "    print(f\"{factor}: {top_1_acc}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
